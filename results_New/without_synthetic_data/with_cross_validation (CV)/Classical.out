
Model: Logistic Regression
Fold 1/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 1:
                precision    recall  f1-score   support

    open-ended       0.74      0.68      0.71       464
 option-posing       0.71      0.87      0.78       764
none-questions       0.92      0.62      0.74       181
       leading       0.86      0.52      0.65       192

      accuracy                           0.74      1601
     macro avg       0.81      0.67      0.72      1601
  weighted avg       0.76      0.74      0.74      1601

Fold 2/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 2:
                precision    recall  f1-score   support

    open-ended       0.76      0.62      0.68       463
 option-posing       0.69      0.87      0.77       765
none-questions       0.88      0.64      0.74       181
       leading       0.82      0.56      0.67       192

      accuracy                           0.73      1601
     macro avg       0.79      0.67      0.71      1601
  weighted avg       0.75      0.73      0.73      1601

Fold 3/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 3:
                precision    recall  f1-score   support

    open-ended       0.78      0.65      0.71       463
 option-posing       0.69      0.88      0.77       764
none-questions       0.97      0.52      0.68       182
       leading       0.74      0.58      0.65       192

      accuracy                           0.73      1601
     macro avg       0.80      0.66      0.70      1601
  weighted avg       0.75      0.73      0.73      1601

Total time taken (training + evaluation): 0.59 seconds
GPU memory used: 0.00 MB
Cross-Validation Accuracies: [0.7432854465958776, 0.7326670830730794, 0.7332916926920675]
Average Cross-Validation Accuracy: 0.7364
--------------------------------------------------

Model: SVM
Fold 1/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 1:
                precision    recall  f1-score   support

    open-ended       0.75      0.68      0.71       464
 option-posing       0.72      0.86      0.78       764
none-questions       0.90      0.67      0.77       181
       leading       0.84      0.58      0.69       192

      accuracy                           0.75      1601
     macro avg       0.80      0.70      0.74      1601
  weighted avg       0.76      0.75      0.75      1601

Fold 2/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 2:
                precision    recall  f1-score   support

    open-ended       0.76      0.66      0.71       463
 option-posing       0.71      0.85      0.77       765
none-questions       0.86      0.67      0.75       181
       leading       0.77      0.61      0.68       192

      accuracy                           0.74      1601
     macro avg       0.78      0.70      0.73      1601
  weighted avg       0.75      0.74      0.74      1601

Fold 3/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 3:
                precision    recall  f1-score   support

    open-ended       0.76      0.66      0.71       463
 option-posing       0.70      0.85      0.77       764
none-questions       0.95      0.58      0.72       182
       leading       0.74      0.64      0.69       192

      accuracy                           0.74      1601
     macro avg       0.79      0.68      0.72      1601
  weighted avg       0.75      0.74      0.74      1601

Total time taken (training + evaluation): 3.43 seconds
GPU memory used: 0.00 MB
Cross-Validation Accuracies: [0.7526545908806995, 0.7432854465958776, 0.7401623985009369]
Average Cross-Validation Accuracy: 0.7454
--------------------------------------------------

Model: Random Forest
Fold 1/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 1:
                precision    recall  f1-score   support

    open-ended       0.82      0.61      0.70       464
 option-posing       0.67      0.91      0.77       764
none-questions       0.89      0.69      0.78       181
       leading       0.90      0.39      0.54       192

      accuracy                           0.73      1601
     macro avg       0.82      0.65      0.70      1601
  weighted avg       0.77      0.73      0.72      1601

Fold 2/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 2:
                precision    recall  f1-score   support

    open-ended       0.79      0.54      0.64       463
 option-posing       0.66      0.90      0.76       765
none-questions       0.86      0.67      0.76       181
       leading       0.79      0.41      0.54       192

      accuracy                           0.71      1601
     macro avg       0.77      0.63      0.67      1601
  weighted avg       0.73      0.71      0.70      1601

Fold 3/3
Train size: 3202, Validation size (real-world only): 1601
Classification Report for Fold 3:
                precision    recall  f1-score   support

    open-ended       0.83      0.54      0.66       463
 option-posing       0.66      0.94      0.77       764
none-questions       0.97      0.64      0.77       182
       leading       0.84      0.40      0.54       192

      accuracy                           0.72      1601
     macro avg       0.83      0.63      0.69      1601
  weighted avg       0.77      0.72      0.71      1601

Total time taken (training + evaluation): 6.14 seconds
GPU memory used: 0.00 MB
Cross-Validation Accuracies: [0.7345409119300437, 0.7095565271705184, 0.7245471580262336]
Average Cross-Validation Accuracy: 0.7229
--------------------------------------------------

Best Model: SVM with Average Accuracy: 0.7454
Classification Report for Best Model:
                precision    recall  f1-score   support

    open-ended       0.76      0.67      0.71      1390
 option-posing       0.71      0.85      0.78      2293
none-questions       0.90      0.64      0.75       544
       leading       0.78      0.61      0.69       576

      accuracy                           0.75      4803
     macro avg       0.79      0.69      0.73      4803
  weighted avg       0.75      0.75      0.74      4803

Confusion matrix saved to /work/nikki/CM_Classical_SVM
