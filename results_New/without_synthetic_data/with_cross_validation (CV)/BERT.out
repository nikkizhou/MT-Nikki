Map:   0%|          | 0/4803 [00:00<?, ? examples/s]Map:  42%|████▏     | 2000/4803 [00:00<00:00, 4589.61 examples/s]Map:  83%|████████▎ | 4000/4803 [00:00<00:00, 7163.97 examples/s]Map: 100%|██████████| 4803/4803 [00:00<00:00, 6866.56 examples/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Fold 1/3 - Training set size: 3202, Validation set size: 1601
Flattening the indices:   0%|          | 0/3202 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 44566.06 examples/s]
Flattening the indices:   0%|          | 0/1601 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1601/1601 [00:00<00:00, 67034.84 examples/s]
Accuracy Fold 1: 0.9232
Total time taken (training + evaluation): 165.70 seconds
GPU memory used: 869.50 MB
Validation Classification Report Fold 1:
                precision    recall  f1-score   support

    open-ended       0.93      0.94      0.93       464
 option-posing       0.93      0.92      0.93       764
none-questions       0.92      0.86      0.89       181
       leading       0.87      0.94      0.91       192

      accuracy                           0.92      1601
     macro avg       0.91      0.92      0.91      1601
  weighted avg       0.92      0.92      0.92      1601

Confusion matrix saved to /work/nikki/CM_BERT_Fold 1.png
Fold 2/3 - Training set size: 3202, Validation set size: 1601
Flattening the indices:   0%|          | 0/3202 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 42843.39 examples/s]
Flattening the indices:   0%|          | 0/1601 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1601/1601 [00:00<00:00, 66093.31 examples/s]
Accuracy Fold 2: 0.9663
Total time taken (training + evaluation): 164.45 seconds
GPU memory used: -7.35 MB
Validation Classification Report Fold 2:
                precision    recall  f1-score   support

    open-ended       0.98      0.95      0.96       463
 option-posing       0.97      0.97      0.97       765
none-questions       0.93      0.94      0.94       181
       leading       0.97      1.00      0.98       192

      accuracy                           0.97      1601
     macro avg       0.96      0.97      0.96      1601
  weighted avg       0.97      0.97      0.97      1601

Confusion matrix saved to /work/nikki/CM_BERT_Fold 2.png
Fold 3/3 - Training set size: 3202, Validation set size: 1601
Flattening the indices:   0%|          | 0/3202 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 42270.17 examples/s]
Flattening the indices:   0%|          | 0/1601 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1601/1601 [00:00<00:00, 63546.45 examples/s]
Accuracy Fold 3: 0.9931
Total time taken (training + evaluation): 165.60 seconds
GPU memory used: 3.23 MB
Validation Classification Report Fold 3:
                precision    recall  f1-score   support

    open-ended       0.99      0.99      0.99       463
 option-posing       0.99      0.99      0.99       764
none-questions       0.99      0.99      0.99       182
       leading       0.99      1.00      1.00       192

      accuracy                           0.99      1601
     macro avg       0.99      0.99      0.99      1601
  weighted avg       0.99      0.99      0.99      1601

Confusion matrix saved to /work/nikki/CM_BERT_Fold 3.png
Total time taken (training + evaluation) all folds: 497.06 seconds
GPU memory used all folds: 865.38 MB

Average Accuracy across all folds: 0.9609
