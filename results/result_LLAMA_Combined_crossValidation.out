DataFrame columns: ['Question', 'labels']
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 2187 examples [00:00, 277128.18 examples/s]
Map:   0%|          | 0/2187 [00:00<?, ? examples/s]Map:  91%|█████████▏| 2000/2187 [00:00<00:00, 15871.46 examples/s]Map: 100%|██████████| 2187/2187 [00:00<00:00, 15030.10 examples/s]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Fold 1/5
Flattening the indices:   0%|          | 0/1749 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1749/1749 [00:00<00:00, 50880.07 examples/s]
Flattening the indices:   0%|          | 0/438 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 438/438 [00:00<00:00, 58276.40 examples/s]
/work/nikki/miniconda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/nikki/miniconda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/nikki/miniconda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Accuracy: 0.8653

Classification Report:
               precision    recall  f1-score   support

   invitation       0.90      0.56      0.69        16
    directive       0.80      0.89      0.84       109
option-posing       0.89      0.93      0.91       293
   suggestive       0.00      0.00      0.00        20

     accuracy                           0.87       438
    macro avg       0.65      0.60      0.61       438
 weighted avg       0.83      0.87      0.84       438


Fold 2/5
Flattening the indices:   0%|          | 0/1749 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1749/1749 [00:00<00:00, 57459.82 examples/s]
Flattening the indices:   0%|          | 0/438 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 438/438 [00:00<00:00, 64917.67 examples/s]
Accuracy: 0.8425

Classification Report:
               precision    recall  f1-score   support

   invitation       0.88      0.47      0.61        15
    directive       0.88      0.76      0.82       131
option-posing       0.84      0.94      0.89       273
   suggestive       0.56      0.26      0.36        19

     accuracy                           0.84       438
    macro avg       0.79      0.61      0.67       438
 weighted avg       0.84      0.84      0.83       438


Fold 3/5
Flattening the indices:   0%|          | 0/1750 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1750/1750 [00:00<00:00, 56477.86 examples/s]
Flattening the indices:   0%|          | 0/437 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 437/437 [00:00<00:00, 60756.79 examples/s]
Accuracy: 0.9245

Classification Report:
               precision    recall  f1-score   support

   invitation       1.00      0.73      0.85        15
    directive       0.90      0.95      0.92       130
option-posing       0.93      0.97      0.95       277
   suggestive       1.00      0.13      0.24        15

     accuracy                           0.92       437
    macro avg       0.96      0.70      0.74       437
 weighted avg       0.93      0.92      0.91       437


Fold 4/5
Flattening the indices:   0%|          | 0/1750 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1750/1750 [00:00<00:00, 53202.90 examples/s]
Flattening the indices:   0%|          | 0/437 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 437/437 [00:00<00:00, 60174.35 examples/s]
Accuracy: 0.9199

Classification Report:
               precision    recall  f1-score   support

   invitation       0.80      0.89      0.84         9
    directive       0.95      0.90      0.92       127
option-posing       0.91      0.98      0.95       280
   suggestive       1.00      0.24      0.38        21

     accuracy                           0.92       437
    macro avg       0.92      0.75      0.77       437
 weighted avg       0.92      0.92      0.91       437


Fold 5/5
Flattening the indices:   0%|          | 0/1750 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1750/1750 [00:00<00:00, 60233.81 examples/s]
Flattening the indices:   0%|          | 0/437 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 437/437 [00:00<00:00, 67910.74 examples/s]
Accuracy: 0.9245

Classification Report:
               precision    recall  f1-score   support

   invitation       0.88      1.00      0.93        14
    directive       0.98      0.93      0.95       135
option-posing       0.90      0.99      0.95       260
   suggestive       1.00      0.25      0.40        28

     accuracy                           0.92       437
    macro avg       0.94      0.79      0.81       437
 weighted avg       0.93      0.92      0.91       437


Average Accuracy across all folds: 0.8953
