Total synthetic samples: 4368

Map:   0%|          | 0/9171 [00:00<?, ? examples/s]
Map:  11%|█         | 1000/9171 [00:00<00:01, 6005.72 examples/s]
Map:  33%|███▎      | 3000/9171 [00:00<00:00, 10294.05 examples/s]
Map:  55%|█████▍    | 5000/9171 [00:00<00:00, 5342.32 examples/s] 
Map:  76%|███████▋  | 7000/9171 [00:00<00:00, 7487.15 examples/s]
Map:  98%|█████████▊| 9000/9171 [00:01<00:00, 9333.01 examples/s]
Map: 100%|██████████| 9171/9171 [00:01<00:00, 8090.85 examples/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Fold 1/3 - Training set size: 6114, Validation set size: 1621

Flattening the indices:   0%|          | 0/6114 [00:00<?, ? examples/s]
Flattening the indices:  98%|█████████▊| 6000/6114 [00:00<00:00, 40847.84 examples/s]
Flattening the indices: 100%|██████████| 6114/6114 [00:00<00:00, 40059.26 examples/s]

Flattening the indices:   0%|          | 0/1621 [00:00<?, ? examples/s]
Flattening the indices: 100%|██████████| 1621/1621 [00:00<00:00, 53838.70 examples/s]
Accuracy Fold 1: 0.8902
Validation Classification Report Fold 1:
                precision    recall  f1-score   support

    open-ended       0.94      0.88      0.91       480
 option-posing       0.91      0.89      0.90       764
none-questions       0.83      0.88      0.85       188
       leading       0.78      0.95      0.85       189

      accuracy                           0.89      1621
     macro avg       0.86      0.90      0.88      1621
  weighted avg       0.89      0.89      0.89      1621

Confusion matrix saved to /work/nikki/CM_DistilBert_Fold_1.png


Fold 2/3 - Training set size: 6114, Validation set size: 1584

Flattening the indices:   0%|          | 0/6114 [00:00<?, ? examples/s]
Flattening the indices:  82%|████████▏ | 5000/6114 [00:00<00:00, 42593.44 examples/s]
Flattening the indices: 100%|██████████| 6114/6114 [00:00<00:00, 39703.50 examples/s]

Flattening the indices:   0%|          | 0/1584 [00:00<?, ? examples/s]
Flattening the indices: 100%|██████████| 1584/1584 [00:00<00:00, 68653.92 examples/s]
Accuracy Fold 2: 0.9602
Validation Classification Report Fold 2:
                precision    recall  f1-score   support

    open-ended       0.99      0.93      0.96       446
 option-posing       0.96      0.98      0.97       765
none-questions       0.90      0.96      0.93       177
       leading       0.95      0.95      0.95       196

      accuracy                           0.96      1584
     macro avg       0.95      0.96      0.95      1584
  weighted avg       0.96      0.96      0.96      1584

Confusion matrix saved to /work/nikki/CM_DistilBert_Fold_2.png


Fold 3/3 - Training set size: 6114, Validation set size: 1598

Flattening the indices:   0%|          | 0/6114 [00:00<?, ? examples/s]
Flattening the indices:  82%|████████▏ | 5000/6114 [00:00<00:00, 34165.03 examples/s]
Flattening the indices: 100%|██████████| 6114/6114 [00:00<00:00, 32424.73 examples/s]

Flattening the indices:   0%|          | 0/1598 [00:00<?, ? examples/s]
Flattening the indices: 100%|██████████| 1598/1598 [00:00<00:00, 54789.86 examples/s]
Early stopping triggered at epoch 3
Accuracy Fold 3: 0.9812
Validation Classification Report Fold 3:
                precision    recall  f1-score   support

    open-ended       0.98      0.98      0.98       464
 option-posing       0.98      0.98      0.98       764
none-questions       0.98      0.96      0.97       179
       leading       0.97      1.00      0.99       191

      accuracy                           0.98      1598
     macro avg       0.98      0.98      0.98      1598
  weighted avg       0.98      0.98      0.98      1598

Confusion matrix saved to /work/nikki/CM_DistilBert_Fold_3.png

Average Accuracy across all folds: 0.9439
