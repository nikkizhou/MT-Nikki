Total synthetic samples: 4368
Map:   0%|          | 0/9171 [00:00<?, ? examples/s]Map:  22%|██▏       | 2000/9171 [00:00<00:01, 4706.73 examples/s]Map:  33%|███▎      | 3000/9171 [00:00<00:01, 5289.64 examples/s]Map:  44%|████▎     | 4000/9171 [00:00<00:00, 5228.93 examples/s]Map:  55%|█████▍    | 5000/9171 [00:01<00:00, 4628.35 examples/s]Map:  87%|████████▋ | 8000/9171 [00:01<00:00, 8525.63 examples/s]Map: 100%|██████████| 9171/9171 [00:01<00:00, 9107.30 examples/s]Map: 100%|██████████| 9171/9171 [00:01<00:00, 7076.53 examples/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Fold 1/3 - Training set size: 6114, Validation set size: 1621
Flattening the indices:   0%|          | 0/6114 [00:00<?, ? examples/s]Flattening the indices:  65%|██████▌   | 4000/6114 [00:00<00:00, 28475.15 examples/s]Flattening the indices: 100%|██████████| 6114/6114 [00:00<00:00, 25768.46 examples/s]
Flattening the indices:   0%|          | 0/1621 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1621/1621 [00:00<00:00, 39582.96 examples/s]
Accuracy: 0.9025

Classification Report:
                precision    recall  f1-score   support

    open-ended       0.90      0.93      0.91       480
 option-posing       0.94      0.88      0.91       764
none-questions       0.82      0.92      0.86       188
       leading       0.86      0.92      0.89       189

      accuracy                           0.90      1621
     macro avg       0.88      0.91      0.89      1621
  weighted avg       0.91      0.90      0.90      1621

Confusion matrix saved to /work/nikki/CM_BERT_Fold_0.png
Fold 2/3 - Training set size: 6114, Validation set size: 1584
Flattening the indices:   0%|          | 0/6114 [00:00<?, ? examples/s]Flattening the indices:  82%|████████▏ | 5000/6114 [00:00<00:00, 29381.18 examples/s]Flattening the indices: 100%|██████████| 6114/6114 [00:00<00:00, 27493.11 examples/s]
Flattening the indices:   0%|          | 0/1584 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1584/1584 [00:00<00:00, 46252.65 examples/s]
Accuracy: 0.9773

Classification Report:
                precision    recall  f1-score   support

    open-ended       0.98      0.98      0.98       446
 option-posing       0.98      0.98      0.98       765
none-questions       0.95      0.97      0.96       177
       leading       0.99      0.96      0.98       196

      accuracy                           0.98      1584
     macro avg       0.97      0.97      0.97      1584
  weighted avg       0.98      0.98      0.98      1584

Confusion matrix saved to /work/nikki/CM_BERT_Fold_1.png
Fold 3/3 - Training set size: 6114, Validation set size: 1598
Flattening the indices:   0%|          | 0/6114 [00:00<?, ? examples/s]Flattening the indices:  65%|██████▌   | 4000/6114 [00:00<00:00, 26581.52 examples/s]Flattening the indices: 100%|██████████| 6114/6114 [00:00<00:00, 24586.30 examples/s]
Flattening the indices:   0%|          | 0/1598 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1598/1598 [00:00<00:00, 44523.33 examples/s]
Early stopping triggered at epoch 3
Accuracy: 0.9875

Classification Report:
                precision    recall  f1-score   support

    open-ended       0.99      0.99      0.99       464
 option-posing       0.99      0.99      0.99       764
none-questions       0.98      0.97      0.97       179
       leading       0.98      1.00      0.99       191

      accuracy                           0.99      1598
     macro avg       0.99      0.99      0.99      1598
  weighted avg       0.99      0.99      0.99      1598

Confusion matrix saved to /work/nikki/CM_BERT_Fold_2.png

Average Accuracy across all folds: 0.9558
