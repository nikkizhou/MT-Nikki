/work/nikki/MT/code/service.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'open-ended' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.
  df.loc[(df['Label'] == -1) & (df[category] > 0), 'Label'] = category
File 1 Combined: 
Label
option-posing     1384
open-ended         706
none-questions     544
suggestive          80
multiple             1
Name: count, dtype: int64
Label
1    2293
0    1390
3     577
2     544
Name: count, dtype: int64
Tuning model: Logistic Regression
Fitting 5 folds for each of 10 candidates, totalling 50 fits
Best parameters for LogisticRegression: {'solver': 'liblinear', 'C': 10}
Tuning model: SVM
Fitting 5 folds for each of 10 candidates, totalling 50 fits
Best parameters for SVC: {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}
Tuning model: Random Forest
Fitting 5 folds for each of 10 candidates, totalling 50 fits
Best parameters for RandomForestClassifier: {'n_estimators': 50, 'min_samples_split': 5, 'max_depth': None}

Model: Logistic Regression
Accuracy: 0.7440
Classification Report:
                precision    recall  f1-score   support

    open-ended       0.72      0.70      0.71       278
 option-posing       0.75      0.80      0.78       459
none-questions       0.82      0.73      0.78       109
       leading       0.71      0.62      0.66       115

      accuracy                           0.74       961
     macro avg       0.75      0.71      0.73       961
  weighted avg       0.74      0.74      0.74       961

--------------------------------------------------

Model: SVM
Accuracy: 0.7680
Classification Report:
                precision    recall  f1-score   support

    open-ended       0.78      0.71      0.74       278
 option-posing       0.74      0.86      0.80       459
none-questions       0.88      0.69      0.77       109
       leading       0.79      0.61      0.69       115

      accuracy                           0.77       961
     macro avg       0.80      0.72      0.75       961
  weighted avg       0.77      0.77      0.77       961

--------------------------------------------------

Model: Random Forest
Accuracy: 0.7471
Classification Report:
                precision    recall  f1-score   support

    open-ended       0.85      0.61      0.71       278
 option-posing       0.69      0.93      0.79       459
none-questions       0.91      0.64      0.75       109
       leading       0.84      0.44      0.58       115

      accuracy                           0.75       961
     macro avg       0.82      0.66      0.71       961
  weighted avg       0.78      0.75      0.74       961

--------------------------------------------------

