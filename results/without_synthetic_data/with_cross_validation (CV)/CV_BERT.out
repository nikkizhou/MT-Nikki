Map:   0%|          | 0/4803 [00:00<?, ? examples/s]Map:  21%|██        | 1000/4803 [00:00<00:00, 5987.86 examples/s]Map:  42%|████▏     | 2000/4803 [00:00<00:00, 3558.90 examples/s]Map:  83%|████████▎ | 4000/4803 [00:00<00:00, 5235.13 examples/s]Map: 100%|██████████| 4803/4803 [00:00<00:00, 4902.28 examples/s]Map: 100%|██████████| 4803/4803 [00:00<00:00, 4805.00 examples/s]
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Fold 1/3 - Training set size: 3202, Validation set size: 1601
Flattening the indices:   0%|          | 0/3202 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 28277.72 examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 27858.78 examples/s]
Flattening the indices:   0%|          | 0/1601 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1601/1601 [00:00<00:00, 45819.84 examples/s]
Accuracy Fold 1: 0.9238
Validation Classification Report Fold 1:
                precision    recall  f1-score   support

    open-ended       0.95      0.92      0.94       464
 option-posing       0.91      0.95      0.93       764
none-questions       0.96      0.83      0.89       181
       leading       0.89      0.93      0.91       192

      accuracy                           0.92      1601
     macro avg       0.93      0.91      0.91      1601
  weighted avg       0.92      0.92      0.92      1601

Confusion matrix saved to /work/nikki/CM_BERT_Fold 1.png
Fold 2/3 - Training set size: 3202, Validation set size: 1601
Flattening the indices:   0%|          | 0/3202 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 30584.05 examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 30108.76 examples/s]
Flattening the indices:   0%|          | 0/1601 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1601/1601 [00:00<00:00, 43337.64 examples/s]
Early stopping triggered at epoch 3
Accuracy Fold 2: 0.9532
Validation Classification Report Fold 2:
                precision    recall  f1-score   support

    open-ended       0.94      0.97      0.96       463
 option-posing       0.97      0.94      0.96       765
none-questions       0.90      0.94      0.92       181
       leading       0.95      0.98      0.96       192

      accuracy                           0.95      1601
     macro avg       0.94      0.96      0.95      1601
  weighted avg       0.95      0.95      0.95      1601

Confusion matrix saved to /work/nikki/CM_BERT_Fold 2.png
Fold 3/3 - Training set size: 3202, Validation set size: 1601
Flattening the indices:   0%|          | 0/3202 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 3202/3202 [00:00<00:00, 31867.54 examples/s]
Flattening the indices:   0%|          | 0/1601 [00:00<?, ? examples/s]Flattening the indices: 100%|██████████| 1601/1601 [00:00<00:00, 44125.33 examples/s]
Early stopping triggered at epoch 3
Accuracy Fold 3: 0.9875
Validation Classification Report Fold 3:
                precision    recall  f1-score   support

    open-ended       0.98      0.99      0.98       463
 option-posing       0.99      0.98      0.99       764
none-questions       0.99      1.00      0.99       182
       leading       0.98      0.99      0.99       192

      accuracy                           0.99      1601
     macro avg       0.99      0.99      0.99      1601
  weighted avg       0.99      0.99      0.99      1601

Confusion matrix saved to /work/nikki/CM_BERT_Fold 3.png

Average Accuracy across all folds: 0.9548
